{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example for a simple neural network\n",
    "\n",
    "## Trump by maximum color (2 colors)\n",
    "\n",
    "The inputs to the network are the number of cards of each color. The network should learn to select the color with the largest number of cards of that color.\n",
    "\n",
    "For a simple example, let us assume that there are 5 cards in total for a player and only 2 colors.\n",
    "\n",
    "### Libraries\n",
    "\n",
    "We use the keras library for building, training and evaluating the network. A tutorial for keras can be found on (https://keras.io/) or https://www.tensorflow.org/guide/keras. There are different implementations of keras, here I will use the one build on tensorflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T14:58:23.891805Z",
     "start_time": "2025-12-06T14:58:23.887297Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow import keras"
   ],
   "outputs": [],
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output function\n",
    "\n",
    "We have to encode the output somehow, for two classes, the simplest solution is a single variable that should be 0 if there are more cards of color 0 and 1 if there are more cards of color 1.\n",
    "\n",
    "### Training and label data.\n",
    "\n",
    "So we can prepare some training data. In this simple case, all the possible configurations are actually known.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T14:58:23.941973Z",
     "start_time": "2025-12-06T14:58:23.937017Z"
    }
   },
   "source": [
    "x_train = np.array([\n",
    "    [0, 5],\n",
    "    [1, 4],\n",
    "    [2, 3],\n",
    "    [3, 2],\n",
    "    [4, 1],\n",
    "    [5, 0],\n",
    "], dtype=np.float32)\n",
    "y_train = np.array([1, 1, 1, 0, 0, 0, ], dtype=np.float32)\n",
    "print(x_train)\n",
    "print(y_train)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 5.]\n",
      " [1. 4.]\n",
      " [2. 3.]\n",
      " [3. 2.]\n",
      " [4. 1.]\n",
      " [5. 0.]]\n",
      "[1. 1. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalisation\n",
    "\n",
    "Input data can have different ranges. It is always a good idea (in other words absolutely essential) to normalize the input data. This is usually done into the range 0..1 or -1..1"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T14:58:24.032542Z",
     "start_time": "2025-12-06T14:58:24.029037Z"
    }
   },
   "source": [
    "x_train = x_train / 5.0\n",
    "print(x_train)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.  1. ]\n",
      " [0.2 0.8]\n",
      " [0.4 0.6]\n",
      " [0.6 0.4]\n",
      " [0.8 0.2]\n",
      " [1.  0. ]]\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T14:58:24.102148Z",
     "start_time": "2025-12-06T14:58:24.098484Z"
    }
   },
   "source": [
    "x_train.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 2)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A first network.\n",
    "\n",
    "We will start with a very simple network, where we connect the inputs directly to the output. So there will be 2 variables, the weights for the connection and the bias. The output function is a sigmoid, which takes values between 0 and 1.\n",
    "\n",
    "With keras, we first have to create the type of model we want (Sequential), and can then add layers. In the tensorflow implementation, we have to add the input_shape parameter in the first layer to tell it the format of the input. This does not include the batch dimension."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T14:58:24.228194Z",
     "start_time": "2025-12-06T14:58:24.218222Z"
    }
   },
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid', input_shape=[2]))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\workspace\\hslu\\dl4g\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we have to compile the model and tell it what loss function and optimizer we want to have. We will take a mean squared error for loss function first. (This is actually not optimal and will be corrected in an exercise).\n",
    "\n",
    "Besides the loss, we usually want to look at some metrics. Here we choose accuracy, that measures how often the network makes the correct decision (see last lecture)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T14:58:24.343613Z",
     "start_time": "2025-12-06T14:58:24.336101Z"
    }
   },
   "source": [
    "model.compile(loss='mse',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n"
   ],
   "outputs": [],
   "execution_count": 44
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print some details about the model."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T14:58:24.412592Z",
     "start_time": "2025-12-06T14:58:24.402513Z"
    }
   },
   "source": [
    "model.summary()\n",
    "print(model.get_weights())"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_6\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_16 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │             \u001B[38;5;34m3\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m3\u001B[0m (12.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> (12.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m3\u001B[0m (12.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> (12.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.69407284],\n",
      "       [-0.69947046]], dtype=float32), array([0.], dtype=float32)]\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can either train one batch, or we can use fit to train repeatedly. The result from the training is the loss function and the metric."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T14:58:24.677152Z",
     "start_time": "2025-12-06T14:58:24.531128Z"
    }
   },
   "source": [
    "model.train_on_batch(x_train, y_train)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(0.3650479, dtype=float32), array(0., dtype=float32)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now try to fit the data in minibatches multiple times. This will calculate the weights, so as to minimize the loss. We might not always get a good result in the first try and even this very simple network seems to need a large number of training steps."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T14:58:28.512508Z",
     "start_time": "2025-12-06T14:58:24.723754Z"
    }
   },
   "source": [
    "model.fit(x_train, y_train, epochs=100, batch_size=6)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 121ms/step - accuracy: 0.0000e+00 - loss: 0.3649\n",
      "Epoch 2/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - accuracy: 0.0000e+00 - loss: 0.3647\n",
      "Epoch 3/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.0000e+00 - loss: 0.3646\n",
      "Epoch 4/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.0000e+00 - loss: 0.3644\n",
      "Epoch 5/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.0000e+00 - loss: 0.3643\n",
      "Epoch 6/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.0000e+00 - loss: 0.3641\n",
      "Epoch 7/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.0000e+00 - loss: 0.3640\n",
      "Epoch 8/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.0000e+00 - loss: 0.3638\n",
      "Epoch 9/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.0000e+00 - loss: 0.3637\n",
      "Epoch 10/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.0000e+00 - loss: 0.3635\n",
      "Epoch 11/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.0000e+00 - loss: 0.3634\n",
      "Epoch 12/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.0000e+00 - loss: 0.3632\n",
      "Epoch 13/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.0000e+00 - loss: 0.3631\n",
      "Epoch 14/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.0000e+00 - loss: 0.3629\n",
      "Epoch 15/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.0000e+00 - loss: 0.3628\n",
      "Epoch 16/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.0000e+00 - loss: 0.3626\n",
      "Epoch 17/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.0000e+00 - loss: 0.3625\n",
      "Epoch 18/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.0000e+00 - loss: 0.3623\n",
      "Epoch 19/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.0000e+00 - loss: 0.3622\n",
      "Epoch 20/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.0000e+00 - loss: 0.3620\n",
      "Epoch 21/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.0000e+00 - loss: 0.3619\n",
      "Epoch 22/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.0000e+00 - loss: 0.3617\n",
      "Epoch 23/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 80ms/step - accuracy: 0.0000e+00 - loss: 0.3616\n",
      "Epoch 24/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.0000e+00 - loss: 0.3614\n",
      "Epoch 25/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.0000e+00 - loss: 0.3613\n",
      "Epoch 26/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - accuracy: 0.0000e+00 - loss: 0.3611\n",
      "Epoch 27/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.0000e+00 - loss: 0.3610\n",
      "Epoch 28/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.0000e+00 - loss: 0.3608\n",
      "Epoch 29/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.0000e+00 - loss: 0.3607\n",
      "Epoch 30/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.0000e+00 - loss: 0.3605\n",
      "Epoch 31/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.0000e+00 - loss: 0.3603\n",
      "Epoch 32/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.0000e+00 - loss: 0.3602\n",
      "Epoch 33/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.0000e+00 - loss: 0.3600\n",
      "Epoch 34/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.0000e+00 - loss: 0.3599\n",
      "Epoch 35/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.0000e+00 - loss: 0.3597\n",
      "Epoch 36/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.0000e+00 - loss: 0.3596\n",
      "Epoch 37/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.0000e+00 - loss: 0.3594\n",
      "Epoch 38/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.0000e+00 - loss: 0.3593\n",
      "Epoch 39/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.0000e+00 - loss: 0.3591\n",
      "Epoch 40/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.0000e+00 - loss: 0.3590\n",
      "Epoch 41/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.0000e+00 - loss: 0.3588\n",
      "Epoch 42/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.0000e+00 - loss: 0.3587\n",
      "Epoch 43/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.0000e+00 - loss: 0.3585\n",
      "Epoch 44/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.0000e+00 - loss: 0.3584\n",
      "Epoch 45/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.0000e+00 - loss: 0.3582\n",
      "Epoch 46/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.0000e+00 - loss: 0.3581\n",
      "Epoch 47/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.0000e+00 - loss: 0.3579\n",
      "Epoch 48/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.0000e+00 - loss: 0.3578\n",
      "Epoch 49/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.0000e+00 - loss: 0.3576\n",
      "Epoch 50/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.0000e+00 - loss: 0.3575\n",
      "Epoch 51/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.0000e+00 - loss: 0.3573\n",
      "Epoch 52/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.0000e+00 - loss: 0.3572\n",
      "Epoch 53/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.0000e+00 - loss: 0.3570\n",
      "Epoch 54/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.0000e+00 - loss: 0.3569\n",
      "Epoch 55/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.0000e+00 - loss: 0.3567\n",
      "Epoch 56/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.0000e+00 - loss: 0.3566\n",
      "Epoch 57/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.0000e+00 - loss: 0.3564\n",
      "Epoch 58/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.0000e+00 - loss: 0.3563\n",
      "Epoch 59/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.0000e+00 - loss: 0.3561\n",
      "Epoch 60/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.0000e+00 - loss: 0.3560\n",
      "Epoch 61/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.0000e+00 - loss: 0.3558\n",
      "Epoch 62/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.0000e+00 - loss: 0.3557\n",
      "Epoch 63/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.0000e+00 - loss: 0.3555\n",
      "Epoch 64/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.0000e+00 - loss: 0.3554\n",
      "Epoch 65/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.0000e+00 - loss: 0.3552\n",
      "Epoch 66/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - accuracy: 0.0000e+00 - loss: 0.3551\n",
      "Epoch 67/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.0000e+00 - loss: 0.3549\n",
      "Epoch 68/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.0000e+00 - loss: 0.3548\n",
      "Epoch 69/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.0000e+00 - loss: 0.3546\n",
      "Epoch 70/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - accuracy: 0.0000e+00 - loss: 0.3545\n",
      "Epoch 71/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.0000e+00 - loss: 0.3543\n",
      "Epoch 72/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - accuracy: 0.0000e+00 - loss: 0.3542\n",
      "Epoch 73/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.0000e+00 - loss: 0.3540\n",
      "Epoch 74/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.0000e+00 - loss: 0.3539\n",
      "Epoch 75/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.0000e+00 - loss: 0.3537\n",
      "Epoch 76/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.0000e+00 - loss: 0.3536\n",
      "Epoch 77/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.0000e+00 - loss: 0.3534\n",
      "Epoch 78/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.0000e+00 - loss: 0.3533\n",
      "Epoch 79/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.0000e+00 - loss: 0.3531\n",
      "Epoch 80/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.0000e+00 - loss: 0.3529\n",
      "Epoch 81/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - accuracy: 0.0000e+00 - loss: 0.3528\n",
      "Epoch 82/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.0000e+00 - loss: 0.3526\n",
      "Epoch 83/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.0000e+00 - loss: 0.3525\n",
      "Epoch 84/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.0000e+00 - loss: 0.3523\n",
      "Epoch 85/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - accuracy: 0.0000e+00 - loss: 0.3522\n",
      "Epoch 86/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.0000e+00 - loss: 0.3520\n",
      "Epoch 87/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - accuracy: 0.0000e+00 - loss: 0.3519\n",
      "Epoch 88/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.0000e+00 - loss: 0.3517\n",
      "Epoch 89/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.0000e+00 - loss: 0.3516\n",
      "Epoch 90/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.0000e+00 - loss: 0.3514\n",
      "Epoch 91/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.0000e+00 - loss: 0.3513\n",
      "Epoch 92/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.0000e+00 - loss: 0.3511\n",
      "Epoch 93/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.0000e+00 - loss: 0.3510\n",
      "Epoch 94/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.0000e+00 - loss: 0.3508\n",
      "Epoch 95/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.0000e+00 - loss: 0.3507\n",
      "Epoch 96/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.0000e+00 - loss: 0.3505\n",
      "Epoch 97/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - accuracy: 0.0000e+00 - loss: 0.3504\n",
      "Epoch 98/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - accuracy: 0.0000e+00 - loss: 0.3502\n",
      "Epoch 99/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.0000e+00 - loss: 0.3501\n",
      "Epoch 100/100\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.0000e+00 - loss: 0.3499\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1cc4dbbae90>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can predict the values from the training value. Why are the results floating point number and not 0 or 1? Does the result seem likely?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T14:58:28.665306Z",
     "start_time": "2025-12-06T14:58:28.592669Z"
    }
   },
   "source": [
    "model.predict(x_train)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.35172385],\n",
       "       [0.40905565],\n",
       "       [0.46897224],\n",
       "       [0.52979696],\n",
       "       [0.58974934],\n",
       "       [0.6471486 ]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also print the found weights for each layer:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T14:58:28.725436Z",
     "start_time": "2025-12-06T14:58:28.720427Z"
    }
   },
   "source": [
    "for layer in model.layers:\n",
    "    weights = layer.get_weights()\n",
    "    print(layer.name)\n",
    "    print(weights)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_16\n",
      "[array([[ 0.6063769],\n",
      "       [-0.6116225]], dtype=float32), array([0.00015208], dtype=float32)]\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we find the actual predictions? We use a threshold on the output of the sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T14:58:28.971311Z",
     "start_time": "2025-12-06T14:58:28.900336Z"
    }
   },
   "source": [
    "model.predict(x_train) > 0.5"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A larger network\n",
    "\n",
    "Lets try a more complicated network with two hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T14:58:29.112707Z",
     "start_time": "2025-12-06T14:58:29.088101Z"
    }
   },
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(2, activation='relu', input_shape=[2]))\n",
    "model.add(keras.layers.Dense(2, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='mse',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\workspace\\hslu\\dl4g\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And train it again..."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T14:58:38.532944Z",
     "start_time": "2025-12-06T14:58:31.037552Z"
    }
   },
   "source": [
    "model.fit(x_train, y_train, epochs=200, batch_size=6)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 213ms/step - accuracy: 0.1667 - loss: 0.2647\n",
      "Epoch 2/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 70ms/step - accuracy: 0.1667 - loss: 0.2645\n",
      "Epoch 3/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.1667 - loss: 0.2643\n",
      "Epoch 4/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.1667 - loss: 0.2642\n",
      "Epoch 5/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.1667 - loss: 0.2640\n",
      "Epoch 6/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - accuracy: 0.3333 - loss: 0.2639\n",
      "Epoch 7/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.3333 - loss: 0.2637\n",
      "Epoch 8/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.3333 - loss: 0.2635\n",
      "Epoch 9/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.3333 - loss: 0.2634\n",
      "Epoch 10/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.3333 - loss: 0.2633\n",
      "Epoch 11/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.3333 - loss: 0.2633\n",
      "Epoch 12/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.3333 - loss: 0.2632\n",
      "Epoch 13/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.3333 - loss: 0.2632\n",
      "Epoch 14/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.3333 - loss: 0.2631\n",
      "Epoch 15/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.3333 - loss: 0.2630\n",
      "Epoch 16/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.3333 - loss: 0.2630\n",
      "Epoch 17/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.3333 - loss: 0.2629\n",
      "Epoch 18/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.3333 - loss: 0.2629\n",
      "Epoch 19/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.3333 - loss: 0.2628\n",
      "Epoch 20/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - accuracy: 0.3333 - loss: 0.2627\n",
      "Epoch 21/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - accuracy: 0.3333 - loss: 0.2627\n",
      "Epoch 22/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - accuracy: 0.3333 - loss: 0.2626\n",
      "Epoch 23/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - accuracy: 0.3333 - loss: 0.2626\n",
      "Epoch 24/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.3333 - loss: 0.2625\n",
      "Epoch 25/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.3333 - loss: 0.2624\n",
      "Epoch 26/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.3333 - loss: 0.2624\n",
      "Epoch 27/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - accuracy: 0.3333 - loss: 0.2623\n",
      "Epoch 28/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.3333 - loss: 0.2623\n",
      "Epoch 29/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.3333 - loss: 0.2622\n",
      "Epoch 30/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.3333 - loss: 0.2621\n",
      "Epoch 31/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.3333 - loss: 0.2621\n",
      "Epoch 32/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.3333 - loss: 0.2620\n",
      "Epoch 33/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.3333 - loss: 0.2620\n",
      "Epoch 34/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.3333 - loss: 0.2619\n",
      "Epoch 35/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.3333 - loss: 0.2619\n",
      "Epoch 36/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.3333 - loss: 0.2618\n",
      "Epoch 37/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.3333 - loss: 0.2617\n",
      "Epoch 38/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.3333 - loss: 0.2617\n",
      "Epoch 39/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.3333 - loss: 0.2616\n",
      "Epoch 40/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.3333 - loss: 0.2616\n",
      "Epoch 41/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.3333 - loss: 0.2615\n",
      "Epoch 42/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.3333 - loss: 0.2614\n",
      "Epoch 43/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.3333 - loss: 0.2614\n",
      "Epoch 44/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.3333 - loss: 0.2613\n",
      "Epoch 45/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.3333 - loss: 0.2613\n",
      "Epoch 46/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.3333 - loss: 0.2612\n",
      "Epoch 47/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - accuracy: 0.3333 - loss: 0.2612\n",
      "Epoch 48/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - accuracy: 0.3333 - loss: 0.2611\n",
      "Epoch 49/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - accuracy: 0.3333 - loss: 0.2610\n",
      "Epoch 50/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.3333 - loss: 0.2610\n",
      "Epoch 51/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.3333 - loss: 0.2609\n",
      "Epoch 52/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.3333 - loss: 0.2609\n",
      "Epoch 53/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.3333 - loss: 0.2608\n",
      "Epoch 54/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.3333 - loss: 0.2608\n",
      "Epoch 55/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.3333 - loss: 0.2607\n",
      "Epoch 56/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.3333 - loss: 0.2607\n",
      "Epoch 57/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.3333 - loss: 0.2606\n",
      "Epoch 58/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.3333 - loss: 0.2605\n",
      "Epoch 59/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.3333 - loss: 0.2605\n",
      "Epoch 60/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.3333 - loss: 0.2604\n",
      "Epoch 61/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.3333 - loss: 0.2604\n",
      "Epoch 62/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - accuracy: 0.3333 - loss: 0.2603\n",
      "Epoch 63/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.3333 - loss: 0.2603\n",
      "Epoch 64/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.3333 - loss: 0.2602\n",
      "Epoch 65/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.3333 - loss: 0.2602\n",
      "Epoch 66/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.3333 - loss: 0.2601\n",
      "Epoch 67/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.3333 - loss: 0.2600\n",
      "Epoch 68/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.3333 - loss: 0.2600\n",
      "Epoch 69/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.3333 - loss: 0.2599\n",
      "Epoch 70/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.3333 - loss: 0.2599\n",
      "Epoch 71/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.3333 - loss: 0.2598\n",
      "Epoch 72/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.3333 - loss: 0.2598\n",
      "Epoch 73/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.3333 - loss: 0.2597\n",
      "Epoch 74/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.3333 - loss: 0.2597\n",
      "Epoch 75/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.3333 - loss: 0.2596\n",
      "Epoch 76/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.3333 - loss: 0.2596\n",
      "Epoch 77/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.3333 - loss: 0.2595\n",
      "Epoch 78/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - accuracy: 0.3333 - loss: 0.2594\n",
      "Epoch 79/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.3333 - loss: 0.2594\n",
      "Epoch 80/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.3333 - loss: 0.2593\n",
      "Epoch 81/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.3333 - loss: 0.2593\n",
      "Epoch 82/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.3333 - loss: 0.2592\n",
      "Epoch 83/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.3333 - loss: 0.2592\n",
      "Epoch 84/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.3333 - loss: 0.2591\n",
      "Epoch 85/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.3333 - loss: 0.2591\n",
      "Epoch 86/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.3333 - loss: 0.2590\n",
      "Epoch 87/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.3333 - loss: 0.2590\n",
      "Epoch 88/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.3333 - loss: 0.2589\n",
      "Epoch 89/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.3333 - loss: 0.2589\n",
      "Epoch 90/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.3333 - loss: 0.2588\n",
      "Epoch 91/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.3333 - loss: 0.2588\n",
      "Epoch 92/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.3333 - loss: 0.2587\n",
      "Epoch 93/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.3333 - loss: 0.2586\n",
      "Epoch 94/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.3333 - loss: 0.2586\n",
      "Epoch 95/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.3333 - loss: 0.2585\n",
      "Epoch 96/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.3333 - loss: 0.2585\n",
      "Epoch 97/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.3333 - loss: 0.2584\n",
      "Epoch 98/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.3333 - loss: 0.2584\n",
      "Epoch 99/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.3333 - loss: 0.2583\n",
      "Epoch 100/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.3333 - loss: 0.2583\n",
      "Epoch 101/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.3333 - loss: 0.2582\n",
      "Epoch 102/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.3333 - loss: 0.2582\n",
      "Epoch 103/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - accuracy: 0.3333 - loss: 0.2581\n",
      "Epoch 104/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.3333 - loss: 0.2581\n",
      "Epoch 105/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.3333 - loss: 0.2580\n",
      "Epoch 106/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.3333 - loss: 0.2580\n",
      "Epoch 107/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.3333 - loss: 0.2579\n",
      "Epoch 108/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.3333 - loss: 0.2579\n",
      "Epoch 109/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.3333 - loss: 0.2578\n",
      "Epoch 110/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.3333 - loss: 0.2578\n",
      "Epoch 111/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.3333 - loss: 0.2577\n",
      "Epoch 112/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.3333 - loss: 0.2577\n",
      "Epoch 113/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.3333 - loss: 0.2576\n",
      "Epoch 114/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.3333 - loss: 0.2576\n",
      "Epoch 115/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.3333 - loss: 0.2575\n",
      "Epoch 116/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.3333 - loss: 0.2575\n",
      "Epoch 117/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.3333 - loss: 0.2574\n",
      "Epoch 118/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.3333 - loss: 0.2574\n",
      "Epoch 119/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.3333 - loss: 0.2573\n",
      "Epoch 120/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.3333 - loss: 0.2573\n",
      "Epoch 121/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.3333 - loss: 0.2572\n",
      "Epoch 122/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.3333 - loss: 0.2572\n",
      "Epoch 123/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.3333 - loss: 0.2572\n",
      "Epoch 124/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.3333 - loss: 0.2571\n",
      "Epoch 125/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.3333 - loss: 0.2571\n",
      "Epoch 126/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.3333 - loss: 0.2570\n",
      "Epoch 127/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.3333 - loss: 0.2570\n",
      "Epoch 128/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.3333 - loss: 0.2569\n",
      "Epoch 129/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.3333 - loss: 0.2569\n",
      "Epoch 130/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.3333 - loss: 0.2568\n",
      "Epoch 131/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.3333 - loss: 0.2568\n",
      "Epoch 132/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.3333 - loss: 0.2567\n",
      "Epoch 133/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.3333 - loss: 0.2567\n",
      "Epoch 134/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.3333 - loss: 0.2566\n",
      "Epoch 135/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.3333 - loss: 0.2566\n",
      "Epoch 136/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.3333 - loss: 0.2565\n",
      "Epoch 137/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 77ms/step - accuracy: 0.3333 - loss: 0.2565\n",
      "Epoch 138/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.3333 - loss: 0.2565\n",
      "Epoch 139/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.3333 - loss: 0.2564\n",
      "Epoch 140/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.3333 - loss: 0.2564\n",
      "Epoch 141/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.3333 - loss: 0.2563\n",
      "Epoch 142/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.3333 - loss: 0.2563\n",
      "Epoch 143/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.3333 - loss: 0.2562\n",
      "Epoch 144/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.3333 - loss: 0.2562\n",
      "Epoch 145/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.3333 - loss: 0.2561\n",
      "Epoch 146/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.3333 - loss: 0.2561\n",
      "Epoch 147/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.3333 - loss: 0.2560\n",
      "Epoch 148/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.3333 - loss: 0.2560\n",
      "Epoch 149/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - accuracy: 0.3333 - loss: 0.2559\n",
      "Epoch 150/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.3333 - loss: 0.2559\n",
      "Epoch 151/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.3333 - loss: 0.2559\n",
      "Epoch 152/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.3333 - loss: 0.2558\n",
      "Epoch 153/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.3333 - loss: 0.2558\n",
      "Epoch 154/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.3333 - loss: 0.2557\n",
      "Epoch 155/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.3333 - loss: 0.2557\n",
      "Epoch 156/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.3333 - loss: 0.2556\n",
      "Epoch 157/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.3333 - loss: 0.2556\n",
      "Epoch 158/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.3333 - loss: 0.2555\n",
      "Epoch 159/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.3333 - loss: 0.2555\n",
      "Epoch 160/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.3333 - loss: 0.2554\n",
      "Epoch 161/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.3333 - loss: 0.2554\n",
      "Epoch 162/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.3333 - loss: 0.2554\n",
      "Epoch 163/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.3333 - loss: 0.2553\n",
      "Epoch 164/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.3333 - loss: 0.2553\n",
      "Epoch 165/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.3333 - loss: 0.2552\n",
      "Epoch 166/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.3333 - loss: 0.2552\n",
      "Epoch 167/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.3333 - loss: 0.2551\n",
      "Epoch 168/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.3333 - loss: 0.2551\n",
      "Epoch 169/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.3333 - loss: 0.2550\n",
      "Epoch 170/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.3333 - loss: 0.2550\n",
      "Epoch 171/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.3333 - loss: 0.2550\n",
      "Epoch 172/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.3333 - loss: 0.2549\n",
      "Epoch 173/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - accuracy: 0.3333 - loss: 0.2549\n",
      "Epoch 174/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.3333 - loss: 0.2548\n",
      "Epoch 175/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - accuracy: 0.3333 - loss: 0.2548\n",
      "Epoch 176/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.3333 - loss: 0.2547\n",
      "Epoch 177/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.3333 - loss: 0.2547\n",
      "Epoch 178/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.3333 - loss: 0.2546\n",
      "Epoch 179/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.3333 - loss: 0.2546\n",
      "Epoch 180/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.3333 - loss: 0.2545\n",
      "Epoch 181/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.3333 - loss: 0.2545\n",
      "Epoch 182/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.3333 - loss: 0.2545\n",
      "Epoch 183/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.3333 - loss: 0.2544\n",
      "Epoch 184/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.3333 - loss: 0.2544\n",
      "Epoch 185/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.3333 - loss: 0.2543\n",
      "Epoch 186/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.3333 - loss: 0.2543\n",
      "Epoch 187/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.3333 - loss: 0.2542\n",
      "Epoch 188/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - accuracy: 0.3333 - loss: 0.2542\n",
      "Epoch 189/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.3333 - loss: 0.2542\n",
      "Epoch 190/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.3333 - loss: 0.2541\n",
      "Epoch 191/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.3333 - loss: 0.2541\n",
      "Epoch 192/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.3333 - loss: 0.2540\n",
      "Epoch 193/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.3333 - loss: 0.2540\n",
      "Epoch 194/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.3333 - loss: 0.2539\n",
      "Epoch 195/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.3333 - loss: 0.2539\n",
      "Epoch 196/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.3333 - loss: 0.2538\n",
      "Epoch 197/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.3333 - loss: 0.2538\n",
      "Epoch 198/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.3333 - loss: 0.2538\n",
      "Epoch 199/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.3333 - loss: 0.2537\n",
      "Epoch 200/200\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.3333 - loss: 0.2537\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1cc4dd46b90>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are not necessarly better, how does the prediction look now?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T14:58:38.723675Z",
     "start_time": "2025-12-06T14:58:38.641120Z"
    }
   },
   "source": [
    "model.predict(x_train)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 8 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001CC4DD57920> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.49326113],\n",
       "       [0.4945824 ],\n",
       "       [0.4959038 ],\n",
       "       [0.49722525],\n",
       "       [0.49854672],\n",
       "       [0.509542  ]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T14:58:38.814465Z",
     "start_time": "2025-12-06T14:58:38.807948Z"
    }
   },
   "source": [
    "for layer in model.layers:\n",
    "    weights = layer.get_weights()\n",
    "    print(layer)\n",
    "    print(weights)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Dense name=dense_17, built=True>\n",
      "[array([[ 0.26253745,  0.02333905],\n",
      "       [-0.9627422 ,  0.72454154]], dtype=float32), array([-0.0641389,  0.0154676], dtype=float32)]\n",
      "<Dense name=dense_18, built=True>\n",
      "[array([[-0.7920411 ,  0.68574125],\n",
      "       [ 0.5716519 , -0.24427614]], dtype=float32), array([-0.00868122, -0.08637725], dtype=float32)]\n",
      "<Dense name=dense_19, built=True>\n",
      "[array([[-0.06593588],\n",
      "       [ 0.9406905 ]], dtype=float32), array([0.00036319], dtype=float32)]\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The larger network, does not seem to work better as the simpler one. Or is it maybe not large enough?\n",
    "\n",
    "The problem is not the network, but the data, we just do not have enough data. So lets try to make up some more data artificially.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T14:58:39.121633Z",
     "start_time": "2025-12-06T14:58:39.117263Z"
    }
   },
   "source": [
    "x_new = np.random.random(size=(10000, 2))\n",
    "y_new = np.zeros(10000, dtype=np.float32)\n",
    "condition = (x_new[:, 1] > x_new[:, 0])\n",
    "y_new[condition] = 1.0"
   ],
   "outputs": [],
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T14:58:50.362086Z",
     "start_time": "2025-12-06T14:58:39.226710Z"
    }
   },
   "source": [
    "model.fit(x_new, y_new, epochs=100, batch_size=100)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 914us/step - accuracy: 0.4507 - loss: 0.2510\n",
      "Epoch 2/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 823us/step - accuracy: 0.4526 - loss: 0.2507\n",
      "Epoch 3/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 796us/step - accuracy: 0.5003 - loss: 0.2504\n",
      "Epoch 4/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 817us/step - accuracy: 0.5011 - loss: 0.2501\n",
      "Epoch 5/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 858us/step - accuracy: 0.5919 - loss: 0.2498\n",
      "Epoch 6/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 839us/step - accuracy: 0.7228 - loss: 0.2495\n",
      "Epoch 7/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 842us/step - accuracy: 0.7283 - loss: 0.2493\n",
      "Epoch 8/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 807us/step - accuracy: 0.7120 - loss: 0.2490\n",
      "Epoch 9/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 897us/step - accuracy: 0.7276 - loss: 0.2487\n",
      "Epoch 10/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 818us/step - accuracy: 0.7220 - loss: 0.2484\n",
      "Epoch 11/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 843us/step - accuracy: 0.7217 - loss: 0.2480\n",
      "Epoch 12/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 829us/step - accuracy: 0.7150 - loss: 0.2477\n",
      "Epoch 13/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 898us/step - accuracy: 0.7225 - loss: 0.2474\n",
      "Epoch 14/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 858us/step - accuracy: 0.7193 - loss: 0.2470\n",
      "Epoch 15/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 875us/step - accuracy: 0.7249 - loss: 0.2466\n",
      "Epoch 16/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 861us/step - accuracy: 0.7222 - loss: 0.2462\n",
      "Epoch 17/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 829us/step - accuracy: 0.7204 - loss: 0.2458\n",
      "Epoch 18/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 887us/step - accuracy: 0.7241 - loss: 0.2453\n",
      "Epoch 19/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 832us/step - accuracy: 0.7271 - loss: 0.2448\n",
      "Epoch 20/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 816us/step - accuracy: 0.7253 - loss: 0.2443\n",
      "Epoch 21/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 846us/step - accuracy: 0.7265 - loss: 0.2437\n",
      "Epoch 22/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 810us/step - accuracy: 0.7276 - loss: 0.2430\n",
      "Epoch 23/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 899us/step - accuracy: 0.7304 - loss: 0.2423\n",
      "Epoch 24/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 863us/step - accuracy: 0.7328 - loss: 0.2415\n",
      "Epoch 25/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 843us/step - accuracy: 0.7348 - loss: 0.2407\n",
      "Epoch 26/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 850us/step - accuracy: 0.7373 - loss: 0.2398\n",
      "Epoch 27/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 868us/step - accuracy: 0.7362 - loss: 0.2387\n",
      "Epoch 28/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 862us/step - accuracy: 0.7409 - loss: 0.2376\n",
      "Epoch 29/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 811us/step - accuracy: 0.7416 - loss: 0.2363\n",
      "Epoch 30/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 860us/step - accuracy: 0.7460 - loss: 0.2349\n",
      "Epoch 31/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 879us/step - accuracy: 0.7492 - loss: 0.2334\n",
      "Epoch 32/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 821us/step - accuracy: 0.7523 - loss: 0.2317\n",
      "Epoch 33/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 853us/step - accuracy: 0.7559 - loss: 0.2298\n",
      "Epoch 34/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 867us/step - accuracy: 0.7596 - loss: 0.2277\n",
      "Epoch 35/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7634 - loss: 0.2254\n",
      "Epoch 36/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 813us/step - accuracy: 0.7674 - loss: 0.2229\n",
      "Epoch 37/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 846us/step - accuracy: 0.7703 - loss: 0.2201\n",
      "Epoch 38/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 825us/step - accuracy: 0.7773 - loss: 0.2171\n",
      "Epoch 39/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 820us/step - accuracy: 0.7813 - loss: 0.2138\n",
      "Epoch 40/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 830us/step - accuracy: 0.7885 - loss: 0.2102\n",
      "Epoch 41/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 858us/step - accuracy: 0.7928 - loss: 0.2064\n",
      "Epoch 42/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 846us/step - accuracy: 0.7987 - loss: 0.2023\n",
      "Epoch 43/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 808us/step - accuracy: 0.8032 - loss: 0.1979\n",
      "Epoch 44/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 852us/step - accuracy: 0.8081 - loss: 0.1933\n",
      "Epoch 45/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 830us/step - accuracy: 0.8144 - loss: 0.1884\n",
      "Epoch 46/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 889us/step - accuracy: 0.8213 - loss: 0.1833\n",
      "Epoch 47/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8267 - loss: 0.1780  \n",
      "Epoch 48/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 832us/step - accuracy: 0.8316 - loss: 0.1725\n",
      "Epoch 49/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 847us/step - accuracy: 0.8397 - loss: 0.1669\n",
      "Epoch 50/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 819us/step - accuracy: 0.8489 - loss: 0.1611\n",
      "Epoch 51/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 863us/step - accuracy: 0.8569 - loss: 0.1552\n",
      "Epoch 52/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 887us/step - accuracy: 0.8681 - loss: 0.1490\n",
      "Epoch 53/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 897us/step - accuracy: 0.8780 - loss: 0.1427\n",
      "Epoch 54/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 930us/step - accuracy: 0.8870 - loss: 0.1365\n",
      "Epoch 55/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 847us/step - accuracy: 0.8956 - loss: 0.1306\n",
      "Epoch 56/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 842us/step - accuracy: 0.9036 - loss: 0.1253\n",
      "Epoch 57/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 841us/step - accuracy: 0.9116 - loss: 0.1204\n",
      "Epoch 58/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 873us/step - accuracy: 0.9169 - loss: 0.1159\n",
      "Epoch 59/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 839us/step - accuracy: 0.9227 - loss: 0.1116\n",
      "Epoch 60/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 858us/step - accuracy: 0.9278 - loss: 0.1075\n",
      "Epoch 61/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 856us/step - accuracy: 0.9334 - loss: 0.1037\n",
      "Epoch 62/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 888us/step - accuracy: 0.9383 - loss: 0.1000\n",
      "Epoch 63/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 856us/step - accuracy: 0.9432 - loss: 0.0966\n",
      "Epoch 64/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 877us/step - accuracy: 0.9479 - loss: 0.0933\n",
      "Epoch 65/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 858us/step - accuracy: 0.9524 - loss: 0.0902\n",
      "Epoch 66/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 888us/step - accuracy: 0.9549 - loss: 0.0873\n",
      "Epoch 67/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 855us/step - accuracy: 0.9595 - loss: 0.0846\n",
      "Epoch 68/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 870us/step - accuracy: 0.9624 - loss: 0.0819\n",
      "Epoch 69/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9658 - loss: 0.0795  \n",
      "Epoch 70/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9683 - loss: 0.0771  \n",
      "Epoch 71/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9711 - loss: 0.0749  \n",
      "Epoch 72/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9731 - loss: 0.0728\n",
      "Epoch 73/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9757 - loss: 0.0709  \n",
      "Epoch 74/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 898us/step - accuracy: 0.9778 - loss: 0.0690\n",
      "Epoch 75/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 848us/step - accuracy: 0.9800 - loss: 0.0672\n",
      "Epoch 76/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 841us/step - accuracy: 0.9819 - loss: 0.0656\n",
      "Epoch 77/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 904us/step - accuracy: 0.9835 - loss: 0.0640\n",
      "Epoch 78/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 864us/step - accuracy: 0.9864 - loss: 0.0625\n",
      "Epoch 79/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 865us/step - accuracy: 0.9865 - loss: 0.0610\n",
      "Epoch 80/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 887us/step - accuracy: 0.9883 - loss: 0.0597\n",
      "Epoch 81/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 858us/step - accuracy: 0.9889 - loss: 0.0584\n",
      "Epoch 82/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 830us/step - accuracy: 0.9903 - loss: 0.0571\n",
      "Epoch 83/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 871us/step - accuracy: 0.9924 - loss: 0.0560\n",
      "Epoch 84/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 859us/step - accuracy: 0.9921 - loss: 0.0548\n",
      "Epoch 85/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 834us/step - accuracy: 0.9924 - loss: 0.0538\n",
      "Epoch 86/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 840us/step - accuracy: 0.9941 - loss: 0.0527\n",
      "Epoch 87/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 846us/step - accuracy: 0.9925 - loss: 0.0517\n",
      "Epoch 88/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 869us/step - accuracy: 0.9939 - loss: 0.0508\n",
      "Epoch 89/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 860us/step - accuracy: 0.9960 - loss: 0.0499\n",
      "Epoch 90/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 877us/step - accuracy: 0.9929 - loss: 0.0490\n",
      "Epoch 91/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 848us/step - accuracy: 0.9960 - loss: 0.0482\n",
      "Epoch 92/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 890us/step - accuracy: 0.9960 - loss: 0.0473\n",
      "Epoch 93/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 844us/step - accuracy: 0.9956 - loss: 0.0466\n",
      "Epoch 94/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 859us/step - accuracy: 0.9948 - loss: 0.0458\n",
      "Epoch 95/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 864us/step - accuracy: 0.9960 - loss: 0.0451\n",
      "Epoch 96/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 865us/step - accuracy: 0.9962 - loss: 0.0444\n",
      "Epoch 97/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 866us/step - accuracy: 0.9968 - loss: 0.0437\n",
      "Epoch 98/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 841us/step - accuracy: 0.9969 - loss: 0.0430\n",
      "Epoch 99/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 859us/step - accuracy: 0.9953 - loss: 0.0424\n",
      "Epoch 100/100\n",
      "\u001B[1m100/100\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 876us/step - accuracy: 0.9951 - loss: 0.0418\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1cc4ddfa310>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 56
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That seems better. Lets look how it performs on our original data."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T14:58:50.579888Z",
     "start_time": "2025-12-06T14:58:50.513635Z"
    }
   },
   "source": [
    "model.predict(x_train)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.99982095],\n",
       "       [0.99598783],\n",
       "       [0.8879264 ],\n",
       "       [0.15249634],\n",
       "       [0.15249634],\n",
       "       [0.1628557 ]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 57
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "We might want to check how the network performs on any data. For this, keras provides the evaluate function that will \n",
    "evaluate the loss and the metrics. So of course label (y) data is needed for that. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T14:58:51.218840Z",
     "start_time": "2025-12-06T14:58:50.835877Z"
    }
   },
   "source": [
    "model.evaluate(x_new, y_new)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 830us/step - accuracy: 0.9982 - loss: 0.0415\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04147570952773094, 0.998199999332428]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 58
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we would normally do that on validation or test data not used during training."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T14:59:03.426495Z",
     "start_time": "2025-12-06T14:59:03.253248Z"
    }
   },
   "source": [
    "x_val_new = np.random.random(size=(5000, 2))\n",
    "y_val_new = np.zeros(5000, dtype=np.float32)\n",
    "y_val_new[x_val_new[:, 1] > x_val_new[:, 0]] = 1.0\n",
    "model.evaluate(x_val_new, y_val_new)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m157/157\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 777us/step - accuracy: 0.9986 - loss: 0.0420\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04198611527681351, 0.9986000061035156]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 59
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation\n",
    "\n",
    "It is essential to visualise the training process to see what is going on. In Keras, an easy method to do this is to use the history object that is returned from fit. It contains the metrics and the loss.\n",
    "\n",
    "We will also split our data into training and validation for this test. We rebuild the model, so that it is initialized again. Otherwise we would just continue with the weights from the previous fit."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T14:59:10.582584Z",
     "start_time": "2025-12-06T14:59:03.517252Z"
    }
   },
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(2, activation='relu', input_shape=[2]))\n",
    "model.add(keras.layers.Dense(2, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='mse',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(x_new, y_new, validation_split=0.25, epochs=50, batch_size=100)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\workspace\\hslu\\dl4g\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.4847 - loss: 0.2507 - val_accuracy: 0.4916 - val_loss: 0.2506\n",
      "Epoch 2/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5077 - loss: 0.2505 - val_accuracy: 0.4916 - val_loss: 0.2505\n",
      "Epoch 3/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5077 - loss: 0.2505 - val_accuracy: 0.4916 - val_loss: 0.2504\n",
      "Epoch 4/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5077 - loss: 0.2504 - val_accuracy: 0.4916 - val_loss: 0.2504\n",
      "Epoch 5/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5077 - loss: 0.2503 - val_accuracy: 0.4916 - val_loss: 0.2503\n",
      "Epoch 6/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5077 - loss: 0.2503 - val_accuracy: 0.4916 - val_loss: 0.2503\n",
      "Epoch 7/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5077 - loss: 0.2502 - val_accuracy: 0.4916 - val_loss: 0.2503\n",
      "Epoch 8/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5077 - loss: 0.2502 - val_accuracy: 0.4916 - val_loss: 0.2503\n",
      "Epoch 9/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5077 - loss: 0.2501 - val_accuracy: 0.4916 - val_loss: 0.2502\n",
      "Epoch 10/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5077 - loss: 0.2501 - val_accuracy: 0.4916 - val_loss: 0.2502\n",
      "Epoch 11/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5077 - loss: 0.2501 - val_accuracy: 0.4916 - val_loss: 0.2502\n",
      "Epoch 12/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5077 - loss: 0.2501 - val_accuracy: 0.4916 - val_loss: 0.2502\n",
      "Epoch 13/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5077 - loss: 0.2501 - val_accuracy: 0.4916 - val_loss: 0.2502\n",
      "Epoch 14/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5077 - loss: 0.2500 - val_accuracy: 0.4916 - val_loss: 0.2502\n",
      "Epoch 15/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5077 - loss: 0.2500 - val_accuracy: 0.4916 - val_loss: 0.2502\n",
      "Epoch 16/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5077 - loss: 0.2500 - val_accuracy: 0.4916 - val_loss: 0.2502\n",
      "Epoch 17/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5077 - loss: 0.2500 - val_accuracy: 0.4916 - val_loss: 0.2502\n",
      "Epoch 18/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5077 - loss: 0.2500 - val_accuracy: 0.4916 - val_loss: 0.2502\n",
      "Epoch 19/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5077 - loss: 0.2500 - val_accuracy: 0.4916 - val_loss: 0.2502\n",
      "Epoch 20/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5077 - loss: 0.2500 - val_accuracy: 0.4916 - val_loss: 0.2502\n",
      "Epoch 21/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5077 - loss: 0.2500 - val_accuracy: 0.4916 - val_loss: 0.2502\n",
      "Epoch 22/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5077 - loss: 0.2500 - val_accuracy: 0.4916 - val_loss: 0.2502\n",
      "Epoch 23/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5077 - loss: 0.2500 - val_accuracy: 0.4916 - val_loss: 0.2502\n",
      "Epoch 24/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5077 - loss: 0.2500 - val_accuracy: 0.4916 - val_loss: 0.2502\n",
      "Epoch 25/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5077 - loss: 0.2500 - val_accuracy: 0.4916 - val_loss: 0.2502\n",
      "Epoch 26/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5077 - loss: 0.2500 - val_accuracy: 0.4916 - val_loss: 0.2502\n",
      "Epoch 27/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5077 - loss: 0.2500 - val_accuracy: 0.4916 - val_loss: 0.2502\n",
      "Epoch 28/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5077 - loss: 0.2500 - val_accuracy: 0.4916 - val_loss: 0.2502\n",
      "Epoch 29/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5077 - loss: 0.2500 - val_accuracy: 0.4916 - val_loss: 0.2502\n",
      "Epoch 30/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5077 - loss: 0.2500 - val_accuracy: 0.4916 - val_loss: 0.2502\n",
      "Epoch 31/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5077 - loss: 0.2500 - val_accuracy: 0.4916 - val_loss: 0.2502\n",
      "Epoch 32/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5077 - loss: 0.2500 - val_accuracy: 0.4916 - val_loss: 0.2502\n",
      "Epoch 33/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5077 - loss: 0.2500 - val_accuracy: 0.4916 - val_loss: 0.2502\n",
      "Epoch 34/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5077 - loss: 0.2500 - val_accuracy: 0.4916 - val_loss: 0.2502\n",
      "Epoch 35/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5077 - loss: 0.2500 - val_accuracy: 0.4916 - val_loss: 0.2502\n",
      "Epoch 36/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5077 - loss: 0.2500 - val_accuracy: 0.4916 - val_loss: 0.2502\n",
      "Epoch 37/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5077 - loss: 0.2500 - val_accuracy: 0.4916 - val_loss: 0.2502\n",
      "Epoch 38/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5077 - loss: 0.2500 - val_accuracy: 0.4916 - val_loss: 0.2502\n",
      "Epoch 39/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5077 - loss: 0.2500 - val_accuracy: 0.4916 - val_loss: 0.2502\n",
      "Epoch 40/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5077 - loss: 0.2500 - val_accuracy: 0.4916 - val_loss: 0.2502\n",
      "Epoch 41/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5077 - loss: 0.2500 - val_accuracy: 0.4916 - val_loss: 0.2502\n",
      "Epoch 42/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5077 - loss: 0.2500 - val_accuracy: 0.4916 - val_loss: 0.2502\n",
      "Epoch 43/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5077 - loss: 0.2500 - val_accuracy: 0.4916 - val_loss: 0.2502\n",
      "Epoch 44/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5077 - loss: 0.2500 - val_accuracy: 0.4916 - val_loss: 0.2502\n",
      "Epoch 45/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5077 - loss: 0.2500 - val_accuracy: 0.4916 - val_loss: 0.2502\n",
      "Epoch 46/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5077 - loss: 0.2499 - val_accuracy: 0.4916 - val_loss: 0.2502\n",
      "Epoch 47/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5077 - loss: 0.2499 - val_accuracy: 0.4916 - val_loss: 0.2502\n",
      "Epoch 48/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5077 - loss: 0.2499 - val_accuracy: 0.4916 - val_loss: 0.2502\n",
      "Epoch 49/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5077 - loss: 0.2499 - val_accuracy: 0.4916 - val_loss: 0.2502\n",
      "Epoch 50/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5077 - loss: 0.2499 - val_accuracy: 0.4916 - val_loss: 0.2502\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T14:59:10.696109Z",
     "start_time": "2025-12-06T14:59:10.692566Z"
    }
   },
   "source": [
    "print(history.history.keys())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['accuracy', 'loss', 'val_accuracy', 'val_loss'])\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-12-06T14:59:10.855010Z",
     "start_time": "2025-12-06T14:59:10.764547Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1cc4de65810>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T14:59:10.951890Z",
     "start_time": "2025-12-06T14:59:10.870940Z"
    }
   },
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('acc')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1cc4d955590>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 63
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Correct loss function\n",
    "\n",
    "The loss function used above (mse) is not optimal. A better loss function would be the crossentropy. Change the network to use that loss function."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T14:59:18.145182Z",
     "start_time": "2025-12-06T14:59:11.010077Z"
    }
   },
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(2, activation='relu', input_shape=[2]))\n",
    "model.add(keras.layers.Dense(2, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(x_new, y_new, validation_split=0.25, epochs=50, batch_size=100)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\workspace\\hslu\\dl4g\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5188 - loss: 0.6854 - val_accuracy: 0.5204 - val_loss: 0.6849\n",
      "Epoch 2/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5607 - loss: 0.6705 - val_accuracy: 0.5764 - val_loss: 0.6730\n",
      "Epoch 3/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6215 - loss: 0.6610 - val_accuracy: 0.6236 - val_loss: 0.6641\n",
      "Epoch 4/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.6533 - loss: 0.6523 - val_accuracy: 0.6500 - val_loss: 0.6559\n",
      "Epoch 5/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.6723 - loss: 0.6434 - val_accuracy: 0.6704 - val_loss: 0.6474\n",
      "Epoch 6/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6887 - loss: 0.6340 - val_accuracy: 0.6828 - val_loss: 0.6383\n",
      "Epoch 7/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7037 - loss: 0.6238 - val_accuracy: 0.6956 - val_loss: 0.6284\n",
      "Epoch 8/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7151 - loss: 0.6128 - val_accuracy: 0.7088 - val_loss: 0.6176\n",
      "Epoch 9/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7305 - loss: 0.6010 - val_accuracy: 0.7204 - val_loss: 0.6061\n",
      "Epoch 10/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7425 - loss: 0.5882 - val_accuracy: 0.7300 - val_loss: 0.5938\n",
      "Epoch 11/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7505 - loss: 0.5746 - val_accuracy: 0.7472 - val_loss: 0.5802\n",
      "Epoch 12/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7661 - loss: 0.5600 - val_accuracy: 0.7596 - val_loss: 0.5659\n",
      "Epoch 13/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7785 - loss: 0.5447 - val_accuracy: 0.7720 - val_loss: 0.5505\n",
      "Epoch 14/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7887 - loss: 0.5286 - val_accuracy: 0.7804 - val_loss: 0.5346\n",
      "Epoch 15/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7996 - loss: 0.5119 - val_accuracy: 0.7892 - val_loss: 0.5182\n",
      "Epoch 16/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8120 - loss: 0.4947 - val_accuracy: 0.8036 - val_loss: 0.5011\n",
      "Epoch 17/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8227 - loss: 0.4769 - val_accuracy: 0.8148 - val_loss: 0.4832\n",
      "Epoch 18/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8353 - loss: 0.4588 - val_accuracy: 0.8284 - val_loss: 0.4651\n",
      "Epoch 19/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8467 - loss: 0.4403 - val_accuracy: 0.8396 - val_loss: 0.4466\n",
      "Epoch 20/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8575 - loss: 0.4219 - val_accuracy: 0.8504 - val_loss: 0.4281\n",
      "Epoch 21/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8683 - loss: 0.4036 - val_accuracy: 0.8592 - val_loss: 0.4100\n",
      "Epoch 22/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8783 - loss: 0.3856 - val_accuracy: 0.8668 - val_loss: 0.3924\n",
      "Epoch 23/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8877 - loss: 0.3681 - val_accuracy: 0.8780 - val_loss: 0.3747\n",
      "Epoch 24/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8987 - loss: 0.3510 - val_accuracy: 0.8896 - val_loss: 0.3575\n",
      "Epoch 25/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9075 - loss: 0.3347 - val_accuracy: 0.8972 - val_loss: 0.3415\n",
      "Epoch 26/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9156 - loss: 0.3191 - val_accuracy: 0.9064 - val_loss: 0.3261\n",
      "Epoch 27/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9243 - loss: 0.3043 - val_accuracy: 0.9132 - val_loss: 0.3115\n",
      "Epoch 28/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9319 - loss: 0.2904 - val_accuracy: 0.9208 - val_loss: 0.2974\n",
      "Epoch 29/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9416 - loss: 0.2774 - val_accuracy: 0.9260 - val_loss: 0.2847\n",
      "Epoch 30/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9472 - loss: 0.2653 - val_accuracy: 0.9364 - val_loss: 0.2725\n",
      "Epoch 31/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9521 - loss: 0.2539 - val_accuracy: 0.9464 - val_loss: 0.2611\n",
      "Epoch 32/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9587 - loss: 0.2435 - val_accuracy: 0.9500 - val_loss: 0.2507\n",
      "Epoch 33/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9639 - loss: 0.2338 - val_accuracy: 0.9572 - val_loss: 0.2411\n",
      "Epoch 34/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9672 - loss: 0.2250 - val_accuracy: 0.9624 - val_loss: 0.2323\n",
      "Epoch 35/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9711 - loss: 0.2167 - val_accuracy: 0.9680 - val_loss: 0.2240\n",
      "Epoch 36/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9753 - loss: 0.2090 - val_accuracy: 0.9724 - val_loss: 0.2165\n",
      "Epoch 37/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9780 - loss: 0.2020 - val_accuracy: 0.9752 - val_loss: 0.2094\n",
      "Epoch 38/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9801 - loss: 0.1954 - val_accuracy: 0.9764 - val_loss: 0.2029\n",
      "Epoch 39/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9820 - loss: 0.1894 - val_accuracy: 0.9808 - val_loss: 0.1964\n",
      "Epoch 40/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9828 - loss: 0.1836 - val_accuracy: 0.9844 - val_loss: 0.1906\n",
      "Epoch 41/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9855 - loss: 0.1783 - val_accuracy: 0.9864 - val_loss: 0.1852\n",
      "Epoch 42/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9868 - loss: 0.1734 - val_accuracy: 0.9860 - val_loss: 0.1802\n",
      "Epoch 43/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9877 - loss: 0.1686 - val_accuracy: 0.9872 - val_loss: 0.1755\n",
      "Epoch 44/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9881 - loss: 0.1642 - val_accuracy: 0.9872 - val_loss: 0.1710\n",
      "Epoch 45/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9891 - loss: 0.1600 - val_accuracy: 0.9888 - val_loss: 0.1667\n",
      "Epoch 46/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9900 - loss: 0.1561 - val_accuracy: 0.9896 - val_loss: 0.1628\n",
      "Epoch 47/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9912 - loss: 0.1523 - val_accuracy: 0.9884 - val_loss: 0.1591\n",
      "Epoch 48/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9907 - loss: 0.1488 - val_accuracy: 0.9904 - val_loss: 0.1553\n",
      "Epoch 49/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9925 - loss: 0.1453 - val_accuracy: 0.9864 - val_loss: 0.1523\n",
      "Epoch 50/50\n",
      "\u001B[1m75/75\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9913 - loss: 0.1421 - val_accuracy: 0.9916 - val_loss: 0.1487\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Maximum of 4 colors\n",
    "\n",
    "Implement a network that will receive 4 colors and has to select one of them.\n",
    "\n",
    "This will require a change of the labels (y) that now take values of 0, 1, 2 or 3. However, networks do not use labels in that form directly for multi class classification, but use 1-hot encoded or categorical data instead.\n",
    "\n",
    "In keras there is a function `keras.utils.to_categorical` that can be used for that.\n",
    "\n",
    "The last layer in the network should then no longer be sigmoid, but the softmax function. And we need the multiclass form of the crossentropy function, which in keras is called `categorical_crossentropy`.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T14:59:22.693161Z",
     "start_time": "2025-12-06T14:59:18.227278Z"
    }
   },
   "source": [
    "x_train = np.random.random(size=(5000, 4))\n",
    "y_train_label = np.argmax(x_train, axis=1)\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train_label, num_classes=4)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(8, activation='relu', input_shape=(4,)))\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(4, activation='sigmoid'))  # match the target variables (one neuron per category)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',  # Multiclass classification loss\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=20, batch_size=32)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\workspace\\hslu\\dl4g\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m157/157\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.4890 - loss: 1.2977\n",
      "Epoch 2/20\n",
      "\u001B[1m157/157\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.6668 - loss: 1.0763\n",
      "Epoch 3/20\n",
      "\u001B[1m157/157\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7152 - loss: 0.8937  \n",
      "Epoch 4/20\n",
      "\u001B[1m157/157\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7750 - loss: 0.7424\n",
      "Epoch 5/20\n",
      "\u001B[1m157/157\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8322 - loss: 0.6128  \n",
      "Epoch 6/20\n",
      "\u001B[1m157/157\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8820 - loss: 0.4970  \n",
      "Epoch 7/20\n",
      "\u001B[1m157/157\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9186 - loss: 0.4051  \n",
      "Epoch 8/20\n",
      "\u001B[1m157/157\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 982us/step - accuracy: 0.9360 - loss: 0.3428\n",
      "Epoch 9/20\n",
      "\u001B[1m157/157\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 857us/step - accuracy: 0.9518 - loss: 0.2992\n",
      "Epoch 10/20\n",
      "\u001B[1m157/157\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 876us/step - accuracy: 0.9588 - loss: 0.2697\n",
      "Epoch 11/20\n",
      "\u001B[1m157/157\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 920us/step - accuracy: 0.9612 - loss: 0.2474\n",
      "Epoch 12/20\n",
      "\u001B[1m157/157\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 962us/step - accuracy: 0.9660 - loss: 0.2289\n",
      "Epoch 13/20\n",
      "\u001B[1m157/157\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 876us/step - accuracy: 0.9648 - loss: 0.2164\n",
      "Epoch 14/20\n",
      "\u001B[1m157/157\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 872us/step - accuracy: 0.9664 - loss: 0.2036\n",
      "Epoch 15/20\n",
      "\u001B[1m157/157\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 859us/step - accuracy: 0.9696 - loss: 0.1934\n",
      "Epoch 16/20\n",
      "\u001B[1m157/157\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 813us/step - accuracy: 0.9724 - loss: 0.1843\n",
      "Epoch 17/20\n",
      "\u001B[1m157/157\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 830us/step - accuracy: 0.9714 - loss: 0.1769\n",
      "Epoch 18/20\n",
      "\u001B[1m157/157\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 913us/step - accuracy: 0.9718 - loss: 0.1697\n",
      "Epoch 19/20\n",
      "\u001B[1m157/157\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 955us/step - accuracy: 0.9704 - loss: 0.1629\n",
      "Epoch 20/20\n",
      "\u001B[1m157/157\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 978us/step - accuracy: 0.9698 - loss: 0.1598\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T14:59:23.063707Z",
     "start_time": "2025-12-06T14:59:22.793189Z"
    }
   },
   "source": [
    "# Testing the model with a sample input\n",
    "x_test = np.random.random(size=(10, 4))\n",
    "y_test_label = np.argmax(x_test, axis=1)\n",
    "y_test = keras.utils.to_categorical(y_test_label, num_classes=4)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Predict\n",
    "predictions = model.predict(x_test)\n",
    "print(\"Predictions:\", np.argmax(predictions, axis=1))\n",
    "print(\"True Labels:\", y_test_label)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 143ms/step - accuracy: 1.0000 - loss: 0.2199\n",
      "Test Loss: 0.2199, Test Accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 10 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001CC5741E700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 51ms/step\n",
      "Predictions: [1 1 1 0 1 1 2 1 3 1]\n",
      "True Labels: [1 1 1 0 1 1 2 1 3 1]\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Implement a ML Network to learn trump from features\n",
    "\n",
    "We would like to train a network to **get the trump** from some features. (We could use the cards directly, but this is deep learning and we will see more of that in next lesson :-) )\n",
    "\n",
    "As features we can use the **number of cards of a color** as before and some of the features from last lecture. For keras all input features should be floating point numbers. Also we need numpy arrays and not pandas. To get the array from a panda, the property `values` can be used."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T14:59:23.132757Z",
     "start_time": "2025-12-06T14:59:23.116166Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "path_to_data = Path('../data')\n",
    "# Import only a fraction of data for efficient testing\n",
    "data = pd.read_csv(path_to_data / '2018_10_18_trump.csv', header=None, nrows=1000)\n",
    "cards = [\n",
    "    # Diamonds\n",
    "    'DA', 'DK', 'DQ', 'DJ', 'D10', 'D9', 'D8', 'D7', 'D6',\n",
    "    # Hearts\n",
    "    'HA', 'HK', 'HQ', 'HJ', 'H10', 'H9', 'H8', 'H7', 'H6',\n",
    "    # Spades\n",
    "    'SA', 'SK', 'SQ', 'SJ', 'S10', 'S9', 'S8', 'S7', 'S6',\n",
    "    # Clubs\n",
    "    'CA', 'CK', 'CQ', 'CJ', 'C10', 'C9', 'C8', 'C7', 'C6'\n",
    "]\n",
    "\n",
    "# Forehand (yes = 1, no = 0)\n",
    "forehand = ['FH']\n",
    "\n",
    "user = ['user']\n",
    "trump = ['trump']\n",
    "\n",
    "feature_columns = forehand\n",
    "\n",
    "data.columns = cards + forehand + user + trump\n",
    "data.drop('user', axis='columns', inplace=True)\n",
    "data.head()\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   DA  DK  DQ  DJ  D10  D9  D8  D7  D6  HA  ...  CK  CQ  CJ  C10  C9  C8  C7  \\\n",
       "0   0   0   0   1    1   0   1   1   0   0  ...   0   1   0    0   0   1   0   \n",
       "1   0   0   0   0    0   0   0   0   1   1  ...   0   0   1    0   0   0   1   \n",
       "2   1   0   0   1    0   0   0   0   0   0  ...   0   1   0    0   0   0   1   \n",
       "3   0   0   0   0    0   0   0   0   0   1  ...   0   0   0    1   1   0   0   \n",
       "4   0   1   0   0    0   0   0   0   1   1  ...   0   0   1    0   0   0   0   \n",
       "\n",
       "   C6  FH  trump  \n",
       "0   0   0      6  \n",
       "1   0   0      5  \n",
       "2   1   0      6  \n",
       "3   0   0      5  \n",
       "4   0   1      4  \n",
       "\n",
       "[5 rows x 38 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DA</th>\n",
       "      <th>DK</th>\n",
       "      <th>DQ</th>\n",
       "      <th>DJ</th>\n",
       "      <th>D10</th>\n",
       "      <th>D9</th>\n",
       "      <th>D8</th>\n",
       "      <th>D7</th>\n",
       "      <th>D6</th>\n",
       "      <th>HA</th>\n",
       "      <th>...</th>\n",
       "      <th>CK</th>\n",
       "      <th>CQ</th>\n",
       "      <th>CJ</th>\n",
       "      <th>C10</th>\n",
       "      <th>C9</th>\n",
       "      <th>C8</th>\n",
       "      <th>C7</th>\n",
       "      <th>C6</th>\n",
       "      <th>FH</th>\n",
       "      <th>trump</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 67
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continue as follows:\n",
    "- Calculate features, \n",
    "- add them to the data set\n",
    "- drop the columns not used\n",
    "- convert to numpy array\n",
    "- build a network and train"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T14:59:23.292196Z",
     "start_time": "2025-12-06T14:59:23.279467Z"
    }
   },
   "source": [
    "data['diamonds_count'] = data.iloc[:, 0:9].sum(axis=1)\n",
    "feature_columns.append('diamonds_count')\n",
    "\n",
    "data['hearts_count'] = data.iloc[:, 9:18].sum(axis=1)\n",
    "feature_columns.append('hearts_count')\n",
    "\n",
    "data['spades_count'] = data.iloc[:, 18:27].sum(axis=1)\n",
    "feature_columns.append('spades_count')\n",
    "\n",
    "data['clubs_count'] = data.iloc[:, 27:36].sum(axis=1)\n",
    "feature_columns.append('clubs_count')\n",
    "\n",
    "data"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     DA  DK  DQ  DJ  D10  D9  D8  D7  D6  HA  ...  C9  C8  C7  C6  FH  trump  \\\n",
       "0     0   0   0   1    1   0   1   1   0   0  ...   0   1   0   0   0      6   \n",
       "1     0   0   0   0    0   0   0   0   1   1  ...   0   0   1   0   0      5   \n",
       "2     1   0   0   1    0   0   0   0   0   0  ...   0   0   1   1   0      6   \n",
       "3     0   0   0   0    0   0   0   0   0   1  ...   1   0   0   0   0      5   \n",
       "4     0   1   0   0    0   0   0   0   1   1  ...   0   0   0   0   1      4   \n",
       "..   ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..    ...   \n",
       "995   0   0   0   0    0   0   0   1   0   0  ...   0   0   1   1   0      6   \n",
       "996   0   1   0   0    0   1   0   0   1   0  ...   1   0   0   0   0      3   \n",
       "997   1   0   1   1    0   0   0   1   0   0  ...   0   0   1   0   1      4   \n",
       "998   0   0   1   0    1   0   0   0   0   0  ...   1   0   1   0   1      2   \n",
       "999   0   1   0   0    0   0   0   0   0   0  ...   1   0   0   0   0      6   \n",
       "\n",
       "     diamonds_count  hearts_count  spades_count  clubs_count  \n",
       "0                 4             0             3            2  \n",
       "1                 1             4             2            2  \n",
       "2                 2             2             2            3  \n",
       "3                 0             3             3            3  \n",
       "4                 2             5             1            1  \n",
       "..              ...           ...           ...          ...  \n",
       "995               1             2             3            3  \n",
       "996               3             2             1            3  \n",
       "997               4             0             2            3  \n",
       "998               2             1             4            2  \n",
       "999               1             4             2            2  \n",
       "\n",
       "[1000 rows x 42 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DA</th>\n",
       "      <th>DK</th>\n",
       "      <th>DQ</th>\n",
       "      <th>DJ</th>\n",
       "      <th>D10</th>\n",
       "      <th>D9</th>\n",
       "      <th>D8</th>\n",
       "      <th>D7</th>\n",
       "      <th>D6</th>\n",
       "      <th>HA</th>\n",
       "      <th>...</th>\n",
       "      <th>C9</th>\n",
       "      <th>C8</th>\n",
       "      <th>C7</th>\n",
       "      <th>C6</th>\n",
       "      <th>FH</th>\n",
       "      <th>trump</th>\n",
       "      <th>diamonds_count</th>\n",
       "      <th>hearts_count</th>\n",
       "      <th>spades_count</th>\n",
       "      <th>clubs_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 42 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T14:59:23.585881Z",
     "start_time": "2025-12-06T14:59:23.572878Z"
    }
   },
   "source": [
    "for color in 'DHSC':\n",
    "    # Jack and nine combination\n",
    "    new_col_J9 = '{}_J9'.format(color)\n",
    "    data[new_col_J9] = data['{}J'.format(color)] & data['{}9'.format(color)]\n",
    "    feature_columns.append(new_col_J9)\n",
    "\n",
    "    # Exercise: Add other features here such as the combination of Ace-King-Queen (Dreiblatt).\n",
    "    # Ace-King-Queen (Dreiblatt) combination\n",
    "    new_col_AKQ = '{}_AKQ'.format(color)\n",
    "    data[new_col_AKQ] = data['{}A'.format(color)] & data['{}K'.format(color)] & data['{}Q'.format(color)]\n",
    "    feature_columns.append(new_col_AKQ)\n",
    "\n",
    "data.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   DA  DK  DQ  DJ  D10  D9  D8  D7  D6  HA  ...  spades_count  clubs_count  \\\n",
       "0   0   0   0   1    1   0   1   1   0   0  ...             3            2   \n",
       "1   0   0   0   0    0   0   0   0   1   1  ...             2            2   \n",
       "2   1   0   0   1    0   0   0   0   0   0  ...             2            3   \n",
       "3   0   0   0   0    0   0   0   0   0   1  ...             3            3   \n",
       "4   0   1   0   0    0   0   0   0   1   1  ...             1            1   \n",
       "\n",
       "   D_J9  D_AKQ  H_J9  H_AKQ  S_J9  S_AKQ  C_J9  C_AKQ  \n",
       "0     0      0     0      0     0      0     0      0  \n",
       "1     0      0     0      0     0      0     0      0  \n",
       "2     0      0     0      0     0      0     0      0  \n",
       "3     0      0     0      0     0      0     0      0  \n",
       "4     0      0     0      1     0      0     0      0  \n",
       "\n",
       "[5 rows x 50 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DA</th>\n",
       "      <th>DK</th>\n",
       "      <th>DQ</th>\n",
       "      <th>DJ</th>\n",
       "      <th>D10</th>\n",
       "      <th>D9</th>\n",
       "      <th>D8</th>\n",
       "      <th>D7</th>\n",
       "      <th>D6</th>\n",
       "      <th>HA</th>\n",
       "      <th>...</th>\n",
       "      <th>spades_count</th>\n",
       "      <th>clubs_count</th>\n",
       "      <th>D_J9</th>\n",
       "      <th>D_AKQ</th>\n",
       "      <th>H_J9</th>\n",
       "      <th>H_AKQ</th>\n",
       "      <th>S_J9</th>\n",
       "      <th>S_AKQ</th>\n",
       "      <th>C_J9</th>\n",
       "      <th>C_AKQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T14:59:36.667410Z",
     "start_time": "2025-12-06T14:59:36.659393Z"
    }
   },
   "source": [
    "data = data.drop(cards, axis=1)\n",
    "data.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   FH  trump  diamonds_count  hearts_count  spades_count  clubs_count  D_J9  \\\n",
       "0   0      6               4             0             3            2     0   \n",
       "1   0      5               1             4             2            2     0   \n",
       "2   0      6               2             2             2            3     0   \n",
       "3   0      5               0             3             3            3     0   \n",
       "4   1      4               2             5             1            1     0   \n",
       "\n",
       "   D_AKQ  H_J9  H_AKQ  S_J9  S_AKQ  C_J9  C_AKQ  \n",
       "0      0     0      0     0      0     0      0  \n",
       "1      0     0      0     0      0     0      0  \n",
       "2      0     0      0     0      0     0      0  \n",
       "3      0     0      0     0      0     0      0  \n",
       "4      0     0      1     0      0     0      0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FH</th>\n",
       "      <th>trump</th>\n",
       "      <th>diamonds_count</th>\n",
       "      <th>hearts_count</th>\n",
       "      <th>spades_count</th>\n",
       "      <th>clubs_count</th>\n",
       "      <th>D_J9</th>\n",
       "      <th>D_AKQ</th>\n",
       "      <th>H_J9</th>\n",
       "      <th>H_AKQ</th>\n",
       "      <th>S_J9</th>\n",
       "      <th>S_AKQ</th>\n",
       "      <th>C_J9</th>\n",
       "      <th>C_AKQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 70
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot-Encode Trump Column"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T14:59:45.107710Z",
     "start_time": "2025-12-06T14:59:45.098620Z"
    }
   },
   "source": [
    "data.trump = data.trump.astype('category')\n",
    "data.trump = data.trump.cat.rename_categories({0: 'DIAMONDS', 1: 'HEARTS', 2: 'SPADES', 3: 'CLUBS',\n",
    "                                               4: 'OBE_ABE', 5: 'UNE_UFE', 6: 'PUSH', 10: 'PUSH'})\n",
    "\n",
    "data.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   FH    trump  diamonds_count  hearts_count  spades_count  clubs_count  D_J9  \\\n",
       "0   0     PUSH               4             0             3            2     0   \n",
       "1   0  UNE_UFE               1             4             2            2     0   \n",
       "2   0     PUSH               2             2             2            3     0   \n",
       "3   0  UNE_UFE               0             3             3            3     0   \n",
       "4   1  OBE_ABE               2             5             1            1     0   \n",
       "\n",
       "   D_AKQ  H_J9  H_AKQ  S_J9  S_AKQ  C_J9  C_AKQ  \n",
       "0      0     0      0     0      0     0      0  \n",
       "1      0     0      0     0      0     0      0  \n",
       "2      0     0      0     0      0     0      0  \n",
       "3      0     0      0     0      0     0      0  \n",
       "4      0     0      1     0      0     0      0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FH</th>\n",
       "      <th>trump</th>\n",
       "      <th>diamonds_count</th>\n",
       "      <th>hearts_count</th>\n",
       "      <th>spades_count</th>\n",
       "      <th>clubs_count</th>\n",
       "      <th>D_J9</th>\n",
       "      <th>D_AKQ</th>\n",
       "      <th>H_J9</th>\n",
       "      <th>H_AKQ</th>\n",
       "      <th>S_J9</th>\n",
       "      <th>S_AKQ</th>\n",
       "      <th>C_J9</th>\n",
       "      <th>C_AKQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>PUSH</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>UNE_UFE</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>PUSH</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>UNE_UFE</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>OBE_ABE</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 71
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T14:59:50.060680Z",
     "start_time": "2025-12-06T14:59:50.050808Z"
    }
   },
   "source": [
    "data = pd.get_dummies(data, ['trump', ])\n",
    "data.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   FH  diamonds_count  hearts_count  spades_count  clubs_count  D_J9  D_AKQ  \\\n",
       "0   0               4             0             3            2     0      0   \n",
       "1   0               1             4             2            2     0      0   \n",
       "2   0               2             2             2            3     0      0   \n",
       "3   0               0             3             3            3     0      0   \n",
       "4   1               2             5             1            1     0      0   \n",
       "\n",
       "   H_J9  H_AKQ  S_J9  S_AKQ  C_J9  C_AKQ  trump_DIAMONDS  trump_HEARTS  \\\n",
       "0     0      0     0      0     0      0           False         False   \n",
       "1     0      0     0      0     0      0           False         False   \n",
       "2     0      0     0      0     0      0           False         False   \n",
       "3     0      0     0      0     0      0           False         False   \n",
       "4     0      1     0      0     0      0           False         False   \n",
       "\n",
       "   trump_SPADES  trump_CLUBS  trump_OBE_ABE  trump_UNE_UFE  trump_PUSH  \n",
       "0         False        False          False          False        True  \n",
       "1         False        False          False           True       False  \n",
       "2         False        False          False          False        True  \n",
       "3         False        False          False           True       False  \n",
       "4         False        False           True          False       False  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FH</th>\n",
       "      <th>diamonds_count</th>\n",
       "      <th>hearts_count</th>\n",
       "      <th>spades_count</th>\n",
       "      <th>clubs_count</th>\n",
       "      <th>D_J9</th>\n",
       "      <th>D_AKQ</th>\n",
       "      <th>H_J9</th>\n",
       "      <th>H_AKQ</th>\n",
       "      <th>S_J9</th>\n",
       "      <th>S_AKQ</th>\n",
       "      <th>C_J9</th>\n",
       "      <th>C_AKQ</th>\n",
       "      <th>trump_DIAMONDS</th>\n",
       "      <th>trump_HEARTS</th>\n",
       "      <th>trump_SPADES</th>\n",
       "      <th>trump_CLUBS</th>\n",
       "      <th>trump_OBE_ABE</th>\n",
       "      <th>trump_UNE_UFE</th>\n",
       "      <th>trump_PUSH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 72
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Features & Target Values"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T14:59:50.480417Z",
     "start_time": "2025-12-06T14:59:50.475544Z"
    }
   },
   "source": [
    "# Split into features (X) and target (y)\n",
    "X = data[feature_columns]\n",
    "y = data[\n",
    "    [\n",
    "        \"trump_DIAMONDS\",\n",
    "        \"trump_HEARTS\",\n",
    "        \"trump_SPADES\",\n",
    "        \"trump_CLUBS\",\n",
    "        \"trump_OBE_ABE\",\n",
    "        \"trump_UNE_UFE\",\n",
    "        \"trump_PUSH\",\n",
    "    ]\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 73
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T14:59:50.683794Z",
     "start_time": "2025-12-06T14:59:50.674840Z"
    }
   },
   "source": [
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both training and test sets\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)"
   ],
   "outputs": [],
   "execution_count": 74
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T14:59:55.168621Z",
     "start_time": "2025-12-06T14:59:50.816940Z"
    }
   },
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(26, activation='relu', input_shape=(X_train_normalized.shape[1],)))\n",
    "model.add(keras.layers.Dense(26, activation='relu'))\n",
    "model.add(\n",
    "    keras.layers.Dense(y_train.shape[1], activation='softmax'))  # match the target variables (one neuron per category)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',  # Multiclass classification loss\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train_normalized, y_train, epochs=50, batch_size=16)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\workspace\\hslu\\dl4g\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.3013 - loss: 1.8660   \n",
      "Epoch 2/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.3850 - loss: 1.7293 \n",
      "Epoch 3/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.3988 - loss: 1.6400 \n",
      "Epoch 4/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.4575 - loss: 1.5594 \n",
      "Epoch 5/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.4975 - loss: 1.4774 \n",
      "Epoch 6/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5275 - loss: 1.4010 \n",
      "Epoch 7/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5400 - loss: 1.3441 \n",
      "Epoch 8/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5312 - loss: 1.3039 \n",
      "Epoch 9/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5437 - loss: 1.2766 \n",
      "Epoch 10/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5487 - loss: 1.2568 \n",
      "Epoch 11/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5437 - loss: 1.2435 \n",
      "Epoch 12/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5575 - loss: 1.2301\n",
      "Epoch 13/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5537 - loss: 1.2209 \n",
      "Epoch 14/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5500 - loss: 1.2133 \n",
      "Epoch 15/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5562 - loss: 1.2038 \n",
      "Epoch 16/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5650 - loss: 1.1973 \n",
      "Epoch 17/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5650 - loss: 1.1896 \n",
      "Epoch 18/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5688 - loss: 1.1879 \n",
      "Epoch 19/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5663 - loss: 1.1837 \n",
      "Epoch 20/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5688 - loss: 1.1763 \n",
      "Epoch 21/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5663 - loss: 1.1723 \n",
      "Epoch 22/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5713 - loss: 1.1701 \n",
      "Epoch 23/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5800 - loss: 1.1660 \n",
      "Epoch 24/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5725 - loss: 1.1631 \n",
      "Epoch 25/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5700 - loss: 1.1600 \n",
      "Epoch 26/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5688 - loss: 1.1572 \n",
      "Epoch 27/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5650 - loss: 1.1538 \n",
      "Epoch 28/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5650 - loss: 1.1475 \n",
      "Epoch 29/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5738 - loss: 1.1485 \n",
      "Epoch 30/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5763 - loss: 1.1504 \n",
      "Epoch 31/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5675 - loss: 1.1484 \n",
      "Epoch 32/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5825 - loss: 1.1427 \n",
      "Epoch 33/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5825 - loss: 1.1381 \n",
      "Epoch 34/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5788 - loss: 1.1365 \n",
      "Epoch 35/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5863 - loss: 1.1351 \n",
      "Epoch 36/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5775 - loss: 1.1323 \n",
      "Epoch 37/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5750 - loss: 1.1315 \n",
      "Epoch 38/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5675 - loss: 1.1325 \n",
      "Epoch 39/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5888 - loss: 1.1299 \n",
      "Epoch 40/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5813 - loss: 1.1273 \n",
      "Epoch 41/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5763 - loss: 1.1275 \n",
      "Epoch 42/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5838 - loss: 1.1272 \n",
      "Epoch 43/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5962 - loss: 1.1234 \n",
      "Epoch 44/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5713 - loss: 1.1268 \n",
      "Epoch 45/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5838 - loss: 1.1157 \n",
      "Epoch 46/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5813 - loss: 1.1251 \n",
      "Epoch 47/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5813 - loss: 1.1199 \n",
      "Epoch 48/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5938 - loss: 1.1185 \n",
      "Epoch 49/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5875 - loss: 1.1194 \n",
      "Epoch 50/50\n",
      "\u001B[1m50/50\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5725 - loss: 1.1182 \n"
     ]
    }
   ],
   "execution_count": 75
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T14:59:55.427738Z",
     "start_time": "2025-12-06T14:59:55.237625Z"
    }
   },
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test_normalized, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "model.save('trump_model.keras')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.5400 - loss: 1.2531  \n",
      "Test Loss: 1.2531, Test Accuracy: 0.5400\n"
     ]
    }
   ],
   "execution_count": 76
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl4g",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
